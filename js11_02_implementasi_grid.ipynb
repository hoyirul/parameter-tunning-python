{"cells":[{"cell_type":"markdown","metadata":{"id":"7fOBsBybzSUX"},"source":["## Implementasi Grid Search\n","\n","Pada jobsheet ini kita akan mencoba mempraktikkan pencarian hyperparameter dengan menggunakan teknik grid search. Scikit-learn sudah menyedaikan fungsi untuk melakukan hal ini, yaitu dengan mengimplementasikan **GridSearchCV** yang dapat diakses melalui package **model selection**.\n","\n","Kasus yang akan kita coba untuk selesaikan adalah kasus WBC, seperti pada jobsheet teori pada modul ini."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18551,"status":"ok","timestamp":1668457288347,"user":{"displayName":"MOCHAMMAD HAIRULLAH","userId":"06941804815695378308"},"user_tz":-420},"id":"ScTbrc09zXcS","outputId":"f2ef78b9-27c9-4206-cfe0-ca10e8fed4f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"cA4DKrJpzSUb"},"source":["### Load dan Pembersihan Data"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":1177,"status":"ok","timestamp":1668457299669,"user":{"displayName":"MOCHAMMAD HAIRULLAH","userId":"06941804815695378308"},"user_tz":-420},"id":"A6Jdj2Z5zSUb","outputId":"e054820c-2970-4d29-d48e-dd1eacd625bf"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-2b32a946-f670-4d2b-b5c4-1bbaea6c129f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>diagnosis</th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>...</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842302</td>\n","      <td>M</td>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.3001</td>\n","      <td>0.14710</td>\n","      <td>...</td>\n","      <td>25.38</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.1622</td>\n","      <td>0.6656</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>842517</td>\n","      <td>M</td>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>...</td>\n","      <td>24.99</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84300903</td>\n","      <td>M</td>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>...</td>\n","      <td>23.57</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>84348301</td>\n","      <td>M</td>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>...</td>\n","      <td>14.91</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>84358402</td>\n","      <td>M</td>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.1980</td>\n","      <td>0.10430</td>\n","      <td>...</td>\n","      <td>22.54</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 32 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b32a946-f670-4d2b-b5c4-1bbaea6c129f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2b32a946-f670-4d2b-b5c4-1bbaea6c129f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2b32a946-f670-4d2b-b5c4-1bbaea6c129f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n","0    842302         M        17.99         10.38          122.80     1001.0   \n","1    842517         M        20.57         17.77          132.90     1326.0   \n","2  84300903         M        19.69         21.25          130.00     1203.0   \n","3  84348301         M        11.42         20.38           77.58      386.1   \n","4  84358402         M        20.29         14.34          135.10     1297.0   \n","\n","   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n","0          0.11840           0.27760          0.3001              0.14710   \n","1          0.08474           0.07864          0.0869              0.07017   \n","2          0.10960           0.15990          0.1974              0.12790   \n","3          0.14250           0.28390          0.2414              0.10520   \n","4          0.10030           0.13280          0.1980              0.10430   \n","\n","   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n","0  ...         25.38          17.33           184.60      2019.0   \n","1  ...         24.99          23.41           158.80      1956.0   \n","2  ...         23.57          25.53           152.50      1709.0   \n","3  ...         14.91          26.50            98.87       567.7   \n","4  ...         22.54          16.67           152.20      1575.0   \n","\n","   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n","0            0.1622             0.6656           0.7119                0.2654   \n","1            0.1238             0.1866           0.2416                0.1860   \n","2            0.1444             0.4245           0.4504                0.2430   \n","3            0.2098             0.8663           0.6869                0.2575   \n","4            0.1374             0.2050           0.4000                0.1625   \n","\n","   symmetry_worst  fractal_dimension_worst  \n","0          0.4601                  0.11890  \n","1          0.2750                  0.08902  \n","2          0.3613                  0.08758  \n","3          0.6638                  0.17300  \n","4          0.2364                  0.07678  \n","\n","[5 rows x 32 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","\n","df = pd.read_csv('./dataset/wbc.csv')\n","\n","# slice kolom terakhir --> Unnamed column\n","df = df.iloc[:,:-1]\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"IXuKf2fCzSUd"},"source":["### Seleksi fitur"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":377,"status":"ok","timestamp":1668457302167,"user":{"displayName":"MOCHAMMAD HAIRULLAH","userId":"06941804815695378308"},"user_tz":-420},"id":"0hID8qN2zSUe","outputId":"c33827e6-74cb-46e5-dd48-86ea3f15bbf5"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-b9d46988-d30c-40ed-bdd3-e8eb9576d635\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>symmetry_mean</th>\n","      <th>fractal_dimension_mean</th>\n","      <th>...</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.3001</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>...</td>\n","      <td>25.38</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.1622</td>\n","      <td>0.6656</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>...</td>\n","      <td>24.99</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>...</td>\n","      <td>23.57</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>...</td>\n","      <td>14.91</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.1980</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>...</td>\n","      <td>22.54</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 30 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9d46988-d30c-40ed-bdd3-e8eb9576d635')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b9d46988-d30c-40ed-bdd3-e8eb9576d635 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b9d46988-d30c-40ed-bdd3-e8eb9576d635');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n","0        17.99         10.38          122.80     1001.0          0.11840   \n","1        20.57         17.77          132.90     1326.0          0.08474   \n","2        19.69         21.25          130.00     1203.0          0.10960   \n","3        11.42         20.38           77.58      386.1          0.14250   \n","4        20.29         14.34          135.10     1297.0          0.10030   \n","\n","   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n","0           0.27760          0.3001              0.14710         0.2419   \n","1           0.07864          0.0869              0.07017         0.1812   \n","2           0.15990          0.1974              0.12790         0.2069   \n","3           0.28390          0.2414              0.10520         0.2597   \n","4           0.13280          0.1980              0.10430         0.1809   \n","\n","   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n","0                 0.07871  ...         25.38          17.33           184.60   \n","1                 0.05667  ...         24.99          23.41           158.80   \n","2                 0.05999  ...         23.57          25.53           152.50   \n","3                 0.09744  ...         14.91          26.50            98.87   \n","4                 0.05883  ...         22.54          16.67           152.20   \n","\n","   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n","0      2019.0            0.1622             0.6656           0.7119   \n","1      1956.0            0.1238             0.1866           0.2416   \n","2      1709.0            0.1444             0.4245           0.4504   \n","3       567.7            0.2098             0.8663           0.6869   \n","4      1575.0            0.1374             0.2050           0.4000   \n","\n","   concave points_worst  symmetry_worst  fractal_dimension_worst  \n","0                0.2654          0.4601                  0.11890  \n","1                0.1860          0.2750                  0.08902  \n","2                0.2430          0.3613                  0.08758  \n","3                0.2575          0.6638                  0.17300  \n","4                0.1625          0.2364                  0.07678  \n","\n","[5 rows x 30 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["X = df.iloc[:, 2:]\n","y = df['diagnosis']\n","\n","X.head()"]},{"cell_type":"markdown","metadata":{"id":"O0MbYQn4zSUe"},"source":["### Split data training dan testing\n","\n","Pada percobaan ini, kita akan mencoba menggunakan teknik repeated k-fold cross validation untuk splitting data training dan testing. Konfigurasi yang akan kita gunakan adalah $k=4$ dan jumlah perulangan 3 kali (*n_repeated=3*). Proses ini juga akan kita jadikan input pada saat melakukan grid search."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1110,"status":"ok","timestamp":1668457305156,"user":{"displayName":"MOCHAMMAD HAIRULLAH","userId":"06941804815695378308"},"user_tz":-420},"id":"2Urw8AJEzSUf"},"outputs":[],"source":["from sklearn.model_selection import RepeatedKFold\n","\n","# inisiasi repated k-fold\n","cv = RepeatedKFold(n_splits=4, n_repeats=3, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"EDiJv9WgzSUg"},"source":["### Implementasi Grid Search\n","\n","selanjutnya, kita akan melakukan tunning parameter dengan menggunakan grid search. Kita akan menggunakan algoritma klasifikasi decision tree. Kemudian, untuk hyperparamater yang akan kita tentukan adalah kriteria split dan kedalaman tree"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19481,"status":"ok","timestamp":1668457325982,"user":{"displayName":"MOCHAMMAD HAIRULLAH","userId":"06941804815695378308"},"user_tz":-420},"id":"oE46Bk4zzSUg","outputId":"a0db29ce-138a-410c-940e-f32667de4984"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","72 fits failed out of a total of 216.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","72 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n","    X_idx_sorted=X_idx_sorted,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n","    criterion = CRITERIA_CLF[self.criterion](\n","KeyError: 'log_loss'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.93555271 0.94024344 0.93086198 0.93203979 0.932048   0.93380446\n"," 0.92674989 0.92147231 0.92149283 0.92206327 0.9279195  0.9279195\n","        nan        nan        nan        nan        nan        nan]\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","72 fits failed out of a total of 216.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","72 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n","    X_idx_sorted=X_idx_sorted,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n","    criterion = CRITERIA_CLF[self.criterion](\n","KeyError: 'log_loss'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.93378804 0.93790013 0.93320529 0.93556092 0.93613956 0.93380856\n"," 0.92851046 0.92498112 0.92618356 0.92791539 0.91970354 0.92147641\n","        nan        nan        nan        nan        nan        nan]\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","72 fits failed out of a total of 216.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","72 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n","    X_idx_sorted=X_idx_sorted,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n","    criterion = CRITERIA_CLF[self.criterion](\n","KeyError: 'log_loss'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.93145294 0.93790834 0.93085787 0.93261844 0.92911373 0.92736137\n"," 0.92968006 0.93377163 0.93025871 0.92674989 0.92382793 0.9267581\n","        nan        nan        nan        nan        nan        nan]\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","72 fits failed out of a total of 216.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","72 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n","    X_idx_sorted=X_idx_sorted,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n","    criterion = CRITERIA_CLF[self.criterion](\n","KeyError: 'log_loss'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.93789602 0.93379215 0.93438311 0.93261433 0.93789602 0.93028333\n"," 0.92732033 0.92498112 0.92791539 0.9255885  0.92909321 0.9179676\n","        nan        nan        nan        nan        nan        nan]\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","72 fits failed out of a total of 216.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","72 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n","    X_idx_sorted=X_idx_sorted,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n","    criterion = CRITERIA_CLF[self.criterion](\n","KeyError: 'log_loss'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.93203979 0.93263075 0.93379215 0.93262665 0.93380446 0.934379\n"," 0.92793181 0.92381152 0.92381972 0.92264602 0.92265833 0.92499343\n","        nan        nan        nan        nan        nan        nan]\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","72 fits failed out of a total of 216.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","72 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n","    X_idx_sorted=X_idx_sorted,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n","    criterion = CRITERIA_CLF[self.criterion](\n","KeyError: 'log_loss'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.92794002 0.93731738 0.93495354 0.93790834 0.9290809  0.93556913\n"," 0.92674989 0.92557208 0.92148462 0.93025871 0.92968006 0.92440248\n","        nan        nan        nan        nan        nan        nan]\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","72 fits failed out of a total of 216.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","72 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n","    X_idx_sorted=X_idx_sorted,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n","    criterion = CRITERIA_CLF[self.criterion](\n","KeyError: 'log_loss'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.93203569 0.93614367 0.93906563 0.93436669 0.9308825  0.93496996\n"," 0.92441068 0.92498112 0.92555977 0.92851866 0.92324518 0.92968006\n","        nan        nan        nan        nan        nan        nan]\n","  category=UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["2.43 s ± 207 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","Hasil evaluasi: 1.0\n","Konfigurasi hyperparameter: {'criterion': 'gini', 'max_depth': 9}\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","72 fits failed out of a total of 216.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","72 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n","    X_idx_sorted=X_idx_sorted,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n","    criterion = CRITERIA_CLF[self.criterion](\n","KeyError: 'log_loss'\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.93438311 0.93438721 0.93438721 0.93494944 0.93556913 0.93087429\n"," 0.9290891  0.92732854 0.9279236  0.93143652 0.92381562 0.92732444\n","        nan        nan        nan        nan        nan        nan]\n","  category=UserWarning,\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","# inisiasi model\n","dt = DecisionTreeClassifier()\n","\n","# Definisikan hyperparameter yang akan digunakan\n","# sklearn menerima dalam bentuk dictionary\n","# nama hyperparamater HARUS SESUAI dengan dokumentasi sklearn\n","params = {\n","    'criterion': ['gini', 'entropy', 'log_loss'],\n","    'max_depth': list(range(5,11))\n","}\n","\n","# inisiasi grid berdasarkan nilai repeated k-fold dan hyperparameter\n","grid = GridSearchCV(dt, param_grid=params, cv=cv)\n","\n","# Fit / latih berdasarkan grid\n","# %timeit merupakan magic command didalam ipython notebook\n","# yang dapat kita gunakan untuk menghitung waktu komputasi\n","# cara ini cukup efektif untuk melakukan evaluasi suatu algoritma atau prosedur\n","%timeit grid.fit(X, y)\n","\n","# Evaluasi dengan score\n","score = grid.score(X,y)\n","\n","print(f'Hasil evaluasi: {score}')\n","print(f'Konfigurasi hyperparameter: {grid.best_params_}')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
